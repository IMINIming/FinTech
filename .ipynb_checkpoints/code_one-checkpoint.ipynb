{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Train Model...\n",
      "[1]\tvalid_0's auc: 0.700645\tvalid_0's l2: 0.169602\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's auc: 0.718038\tvalid_0's l2: 0.16791\n",
      "[3]\tvalid_0's auc: 0.727962\tvalid_0's l2: 0.1659\n",
      "[4]\tvalid_0's auc: 0.73289\tvalid_0's l2: 0.16399\n",
      "[5]\tvalid_0's auc: 0.737483\tvalid_0's l2: 0.162253\n",
      "[6]\tvalid_0's auc: 0.738996\tvalid_0's l2: 0.160632\n",
      "[7]\tvalid_0's auc: 0.738475\tvalid_0's l2: 0.159323\n",
      "[8]\tvalid_0's auc: 0.738576\tvalid_0's l2: 0.158253\n",
      "[9]\tvalid_0's auc: 0.738614\tvalid_0's l2: 0.1569\n",
      "[10]\tvalid_0's auc: 0.739901\tvalid_0's l2: 0.155692\n",
      "[11]\tvalid_0's auc: 0.742875\tvalid_0's l2: 0.15455\n",
      "[12]\tvalid_0's auc: 0.742809\tvalid_0's l2: 0.153619\n",
      "[13]\tvalid_0's auc: 0.74471\tvalid_0's l2: 0.152597\n",
      "[14]\tvalid_0's auc: 0.744375\tvalid_0's l2: 0.15163\n",
      "[15]\tvalid_0's auc: 0.744992\tvalid_0's l2: 0.150958\n",
      "[16]\tvalid_0's auc: 0.745782\tvalid_0's l2: 0.150176\n",
      "[17]\tvalid_0's auc: 0.746477\tvalid_0's l2: 0.149453\n",
      "[18]\tvalid_0's auc: 0.747023\tvalid_0's l2: 0.148695\n",
      "[19]\tvalid_0's auc: 0.746939\tvalid_0's l2: 0.148067\n",
      "[20]\tvalid_0's auc: 0.74762\tvalid_0's l2: 0.147412\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's auc: 0.74762\tvalid_0's l2: 0.147412\n",
      "Save model...\n",
      "[0.33461382 0.18822828 0.15398107 ... 0.33435666 0.16799593 0.16816744]\n"
     ]
    }
   ],
   "source": [
    "#在这部分在之前的特征部分加入了过去60天的交易行为数据\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import  make_classification\n",
    "\n",
    "class Credit_risk_scorePreLR:\n",
    "    def __init__(self):\n",
    "        self.data_train_tag, self.data_train_trd = self.load_train_data()\n",
    "        self.data_test_tag, self.data_test_trd = self.load_test_data()\n",
    "        self.train_data = self.merge_train_data()\n",
    "        self.test_data = self.merge_test_data()\n",
    "        self.train, self.test = self.split_data()\n",
    "\n",
    "    def load_train_data(self):\n",
    "        data_tag= pd.read_csv(\"E:/招行数据比赛/data_b/训练数据集/训练数据集/训练数据集_onehot_tag.csv\")\n",
    "        data_trd = pd.read_csv(\"E:/招行数据比赛/data_b/训练数据集/训练数据集/训练数据集_trd.csv\")\n",
    "        return data_tag, data_trd\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        data_tag= pd.read_csv(\"E:/招行数据比赛/data_b/评分数据集b/b/评分数据集_onehot_tag_b.csv\")\n",
    "        data_trd = pd.read_csv(\"E:/招行数据比赛/data_b/评分数据集b/b/评分数据集_trd_b.csv\")\n",
    "        return data_tag, data_trd\n",
    "    \n",
    "    def trd_data_dig_one(self, type):\n",
    "        if type == 1:\n",
    "            data_trd = self.data_train_trd\n",
    "        if type == 2:\n",
    "            data_trd = self.data_test_trd\n",
    "        data_trd['trx_tm'] = pd.to_datetime(data_trd['trx_tm'])\n",
    "        data_trd = data_trd.set_index('trx_tm')\n",
    "        \n",
    "        #按照周的时间间隔统计不同的收支交易方向的总金额\n",
    "        data_trd_group = data_trd.groupby(['id','Dat_Flg1_Cd']).resample('w').sum()#按照'id','Dat_Flg1_Cd'分组，再按照列trx_tm按周重采样，求和\n",
    "        data_trd_group_weekly_money=data_trd_group.pivot_table(index ='id' , columns= ['trx_tm','Dat_Flg1_Cd'],values='cny_trx_amt' ,aggfunc='sum') .fillna(0)\n",
    "        if type == 1:\n",
    "            data_tag = self.data_train_tag\n",
    "        if type == 2:\n",
    "            data_tag = self.data_test_tag\n",
    "            \n",
    "        data_tag = data_tag.set_index('id')\n",
    "        data = pd.concat([data_tag, data_trd_group_weekly_money], axis = 1)        #将两个表连接到一起\n",
    "        #按照周的时间间隔统计不同的收支交易方向的次数\n",
    "        data_trd_group_times = data_trd.groupby(['id','Dat_Flg1_Cd']).resample('w').count()\n",
    "        data_trd_group_times.drop(['id','Dat_Flg1_Cd'], axis=1, inplace=True)\n",
    "        data_trd_group_weekly_times=data_trd_group_times.pivot_table(index ='id' , columns= ['trx_tm','Dat_Flg1_Cd'],values='cny_trx_amt' ,aggfunc='sum') .fillna(0)\n",
    "        data = pd.concat([data, data_trd_group_weekly_times], axis = 1)\n",
    "        \n",
    "        #按照周的时间间隔统计不同的支付方式的总金额\n",
    "        data_trd_Dat_Flg3_Cd = data_trd.groupby(['id','Dat_Flg3_Cd']).resample('w').sum()\n",
    "        data_trd_Dat_Flg3_Cd_money=data_trd_Dat_Flg3_Cd.pivot_table (index ='id' , columns= ['trx_tm','Dat_Flg3_Cd'],values='cny_trx_amt' ,aggfunc='sum') .fillna(0)\n",
    "        data = pd.concat([data, data_trd_Dat_Flg3_Cd_money], axis = 1)\n",
    "        \n",
    "        #按照周的时间间隔统计不同的支付方式的次数\n",
    "        data_trd_Dat_Flg3_Cd_times = data_trd.groupby(['id','Dat_Flg3_Cd']).resample('w').count()\n",
    "        data_trd_Dat_Flg3_Cd_times.drop(['id','Dat_Flg3_Cd'], axis=1, inplace=True)\n",
    "        data_trd_group_Dat_Flg3_Cd_times=data_trd_Dat_Flg3_Cd_times.pivot_table (index ='id' , columns= ['trx_tm','Dat_Flg3_Cd'],values='cny_trx_amt' ,aggfunc='sum') .fillna(0)\n",
    "        data = pd.concat([data, data_trd_group_Dat_Flg3_Cd_times], axis = 1)\n",
    "        \n",
    "        #按照周的时间间隔统计不同的收支一级分类的总金额\n",
    "        data_trd_Trx_Cod1_Cd = data_trd.groupby(['id','Trx_Cod1_Cd']).resample('w').sum()#按照'id','Trx_Cod1_Cd'分组，再按照列trx_tm按周重采样，求和\n",
    "        data_trd_Trx_Cod1_Cd.drop(['Trx_Cod1_Cd'], axis=1, inplace=True)\n",
    "        data_trd_Trx_Cod1_Cd_weekly_money=data_trd_Trx_Cod1_Cd.pivot_table(index ='id' , columns= ['trx_tm','Trx_Cod1_Cd'],values='cny_trx_amt' ,aggfunc='sum') .fillna(0)\n",
    "        data = pd.concat([data, data_trd_Trx_Cod1_Cd_weekly_money], axis = 1)\n",
    "        \n",
    "        #按照周的时间间隔统计不同的收支一级分类的次数\n",
    "        data_trd_Trx_Cod1_Cd_times = data_trd.groupby(['id','Trx_Cod1_Cd']).resample('w').count()#按照'id','Trx_Cod1_Cd'分组，再按照列trx_tm按周重采样，求和\n",
    "        data_trd_Trx_Cod1_Cd_times.drop(['id','Trx_Cod1_Cd'], axis=1, inplace=True)\n",
    "        data_trd_Trx_Cod1_Cd_weekly_times=data_trd_Trx_Cod1_Cd_times.pivot_table(index ='id' , columns= ['trx_tm','Trx_Cod1_Cd'],values='cny_trx_amt' ,aggfunc='sum') .fillna(0)\n",
    "        data = pd.concat([data, data_trd_Trx_Cod1_Cd_weekly_times], axis = 1)\n",
    "       \n",
    "#         data.to_csv(\"E:/招行数据比赛/data_b/训练数据集/训练数据集/训练数据集_trd1.csv\", index=True)\n",
    "        data = data.reset_index() #重置index\n",
    "        data = data.rename(columns={'index':'id'})\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def trd_data_dig_two(self, type):\n",
    "        if type == 1:\n",
    "            data_trd = self.data_train_trd\n",
    "        if type == 2:\n",
    "            data_trd = self.data_test_trd\n",
    "        data_trd['trx_tm'] = pd.to_datetime(data_trd['trx_tm'], format='%Y/%m/%d')  # 转变为8位时间字符\n",
    "        data_trd['trx_tm'] = data_trd['trx_tm'].dt.strftime('%Y%m%d')\n",
    "        #收支统计特征：总和、最大、最小、均值、标准差、数目\n",
    "        temp1 = data_trd[data_trd['cny_trx_amt'] > 0].groupby(by=['id'], as_index=False)['cny_trx_amt'].agg(\n",
    "        {'income_sum': 'sum', 'income_max': 'max', 'income_min': 'min', 'income_mean': 'mean', 'income_count': 'count',\n",
    "         'income_std': 'std'}) #收入\n",
    "        temp2 = data_trd[data_trd['cny_trx_amt'] < 0].groupby(by=['id'], as_index=False)['cny_trx_amt'].agg(  # 支出为负，min、max互换\n",
    "        {'expend_sum': 'sum', 'expend_max': 'min', 'expend_min': 'max', 'expend_mean': 'mean', 'expend_count': 'count',\n",
    "         'ecpend_std': 'std'}) #支出\n",
    "        temp3 = data_trd.groupby(by=['id'], as_index=False)['cny_trx_amt'].agg({'trd_mean': 'mean', 'trd_std': 'std'})\n",
    "        #收支交易天数\n",
    "        temp4 = data_trd.groupby(by=['id'], as_index=False)['trx_tm'].agg({'trd_day_count': 'nunique'})  # 交易天数\n",
    "        temp5 = data_trd[data_trd['cny_trx_amt'] > 0].groupby(by=['id'], as_index=False)['trx_tm'].agg(\n",
    "        {'income_day_count': 'nunique'})  # 收入天数\n",
    "        temp6 = data_trd[data_trd['cny_trx_amt'] < 0].groupby(by=['id'], as_index=False)['trx_tm'].agg(\n",
    "        {'expend_day_count': 'nunique'})  # 支出天数\n",
    "        data_t = pd.merge(temp3, temp1, on=['id'], how='left')\n",
    "        data_t = pd.merge(data_t, temp2, on=['id'], how='left')\n",
    "        data_t = pd.merge(data_t, temp4, on=['id'], how='left')\n",
    "        data_t = pd.merge(data_t, temp5, on=['id'], how='left')\n",
    "        data_t = pd.merge(data_t, temp6, on=['id'], how='left')\n",
    "\n",
    "        # 求总和\n",
    "        data_t['trd_sum'] = data_t['income_sum'] + data_t['expend_sum']  # 余额\n",
    "        data_t['trd_total'] = data_t['income_sum'] - data_t['expend_sum']  # 总交易额\n",
    "        data_t['trd_count'] = data_t['income_count'] + data_t['expend_count']  # 交易总数\n",
    "        # 收入、支出、交易额求平均\n",
    "        data_t['trd_every_total'] = data_t['trd_total'] / data_t['trd_count']  # 平均每笔交易额\n",
    "        data_t['trd_day_total'] = data_t['trd_total'] / data_t['trd_day_count']  # 平均每天交易额\n",
    "        data_t['income_every_sum'] = data_t['income_sum'] / data_t['income_count']  # 平均每笔收入\n",
    "        data_t['income_day_sum'] = data_t['income_sum'] / data_t['income_day_count']  # 平均每天收入\n",
    "        data_t['expend_every_sum'] = data_t['expend_sum'] / data_t['expend_count']  # 平均每笔支出\n",
    "        data_t['expend_day_sum'] = data_t['expend_sum'] / data_t['expend_day_count']  # 平均每天支出\n",
    "        # 收入数、支出数、交易数求平均\n",
    "        data_t['trd_daymean_count'] = data_t['trd_count'] / data_t['trd_day_count']  # 平均每天交易数\n",
    "        data_t['income_daymean_count'] = data_t['income_count'] / data_t['income_day_count']  # 平均每天收入数\n",
    "        data_t['expend_daymean_count'] = data_t['expend_count'] / data_t['expend_day_count']  # 平均每天支出数\n",
    "        # 数量、交易额占比\n",
    "        data_t['income_count_ratio']=data_t['income_count']/data_t['trd_count']\n",
    "        data_t['expend_count_ratio']=data_t['expend_count']/data_t['trd_count']\n",
    "        data_t['income_total_ratio']=data_t['income_sum']/data_t['trd_total']\n",
    "        data_t['expend_total_ratio']=-data_t['expend_sum']/data_t['trd_total']\n",
    "        return data_t\n",
    "    \n",
    "    def trd_data_dig_three(self, type):\n",
    "        if type == 1:\n",
    "            data_trd = self.data_train_trd\n",
    "        if type == 2:\n",
    "            data_trd = self.data_test_trd\n",
    "        data_trd['trx_tm'] = pd.to_datetime(data_trd['trx_tm'], format='%Y/%m/%d')  # 转变为8位时间字符\n",
    "        data_trd['trx_tm'] = data_trd['trx_tm'].dt.strftime('%Y%m%d')\n",
    "        data_trd['trx_tm'] = data_trd['trx_tm'].astype(float)#转换成int\n",
    "        #交易次数特征\n",
    "        trx_one=data_trd.groupby(['id','trx_tm'])['cny_trx_amt'].count().unstack().reset_index()\n",
    "        col=trx_one.columns.tolist()[1:]\n",
    "        trx_one['trdnum_day_max']=trx_one[col].max(axis=1)    #单日最大交易次数\n",
    "        trx_one=trx_one[['id','trdnum_day_max']]\n",
    "        #交易额特征---不计正负\n",
    "        temp=data_trd[['id','trx_tm','cny_trx_amt']].copy()\n",
    "        temp['cny_trx_amt']=temp['cny_trx_amt'].apply(lambda x:abs(x)) #取绝对值\n",
    "        trx_two=temp.groupby(['id','trx_tm'])['cny_trx_amt'].sum().unstack().reset_index()\n",
    "        col=trx_two.columns.tolist()[1:]\n",
    "        trx_two['trdtotal_day_max']=trx_two[col].max(axis=1)    #单日最大交易额\n",
    "        trx_two['trdtotal_day_min']=trx_two[col].min(axis=1)    #单日最小交易额\n",
    "        trx_two=trx_two[['id','trdtotal_day_max','trdtotal_day_min']]\n",
    "        trx_three=temp.groupby(by=['id'], as_index=False)['cny_trx_amt'].agg(   #单笔最大交易额，单笔最小交易额\n",
    "            {'every_max':'max','every_min':'min'})\n",
    "        trx_two=pd.merge(trx_two, trx_three, on=['id'], how='left')\n",
    "\n",
    "        #余额特征--计算正负值\n",
    "        trx_four=data_trd.groupby(['id','trx_tm'])['cny_trx_amt'].sum().unstack().reset_index()\n",
    "        col=trx_four.columns.tolist()[1:]\n",
    "        trx_four['trdsum_day_max']=trx_four[col].max(axis=1)    #单日最大余额\n",
    "        trx_four['trdsum_day_min']=trx_four[col].min(axis=1)    #单日最小余额\n",
    "        trx_four=trx_four[['id','trdsum_day_max','trdsum_day_min']]\n",
    "        trx_five=data_trd.groupby(by=['id'],as_index=False)['trx_tm'].agg({'trx_date_min':'min',\n",
    "                                                                  'trx_date_max':'max'})  #交易的第一天和最后一天\n",
    "        trx_one=pd.merge(trx_one, trx_two, on=['id'], how='left')\n",
    "        trx_one=pd.merge(trx_one, trx_four, on=['id'], how='left')\n",
    "        trx_one=pd.merge(trx_one, trx_five, on=['id'], how='left')\n",
    "        return trx_one\n",
    "    \n",
    "    def merge_train_data(self):\n",
    "        data_one = self.trd_data_dig_one(1)\n",
    "        data_two = self.trd_data_dig_two(1)\n",
    "        data_three = self.trd_data_dig_three(1)\n",
    "        data = pd.merge(data_one, data_two,on=['id'], how='left') \n",
    "        data = pd.merge(data, data_three,on=['id'], how='left')\n",
    "        cname = []\n",
    "        for i in range(231):\n",
    "            cname.append(i)\n",
    "        data.columns = cname\n",
    "#         data.drop(0 ,axis=1, inplace=True)\n",
    "        data = data.rename(columns={ 0 :'id'})\n",
    "        data = data.rename(columns={ 1 :'flag'})\n",
    "        data.to_csv(\"E:/招行数据比赛/data_b/训练数据集/训练数据集/训练数据集_data.csv\", index=True)\n",
    "        return data\n",
    "    \n",
    "    def merge_test_data(self):\n",
    "        data_one = self.trd_data_dig_one(2)\n",
    "        data_two = self.trd_data_dig_two(2)\n",
    "        data_three = self.trd_data_dig_three(2)\n",
    "        data = pd.merge(data_one, data_two,on=['id'], how='left') \n",
    "        data = pd.merge(data, data_three,on=['id'], how='left') \n",
    "        cname = []\n",
    "        for i in range(230):\n",
    "            cname.append(i)\n",
    "        data.columns = cname\n",
    "#         data.drop(0 ,axis=1, inplace=True)\n",
    "        data = data.rename(columns={ 0 :'id'})\n",
    "        data.to_csv(\"E:/招行数据比赛/data_b/评分数据集b/b/评分数据集_data.csv\", index=True)\n",
    "        return data\n",
    "\n",
    "    #将数据集拆分成训练集和测试集\n",
    "    def split_data(self):\n",
    "        train, test = train_test_split(\n",
    "        self.train_data,\n",
    "        test_size=0.1,\n",
    "        random_state= 40\n",
    "        )\n",
    "        return train, test\n",
    "        \n",
    "    #模型训练\n",
    "    def train_model(self):\n",
    "        label = \"flag\"\n",
    "        ID = \"id\"\n",
    "        x_columns = [x for x in self.train.columns if x not in [label, ID]]\n",
    "        x_train = self.train[x_columns]\n",
    "        y_train = self.train[label]\n",
    "        x_columns1 = [x for x in self.test.columns if x not in [label, ID]]\n",
    "        x_test = self.test[x_columns1]\n",
    "        y_test = self.test[label]\n",
    "        # 转换为Dataset数据格式\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "        # 参数\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',  # 设置提升类型\n",
    "            'objective': 'regression',  # 目标函数\n",
    "            'metric': {'l2', 'auc'},  # 评估函数\n",
    "            'num_leaves': 31,  # 叶子节点数\n",
    "            'learning_rate': 0.05,  # 学习速率\n",
    "            'feature_fraction': 0.9,  # 建树的特征选择比例\n",
    "            'bagging_fraction': 0.8,  # 建树的样本采样比例\n",
    "            'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "            'verbose': 1  # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "        }\n",
    "        # 模型训练\n",
    "        print(\"Start Train Model...\")\n",
    "        gbm = lgb.train(params, lgb_train, num_boost_round=20, valid_sets=lgb_eval, early_stopping_rounds=5)\n",
    "        print('Save model...')\n",
    "        # 保存模型到文件\n",
    "        gbm.save_model('model.txt')\n",
    "        return gbm\n",
    "\n",
    "    #模型评估\n",
    "    def evaluate(self, gbm):\n",
    "        ID = \"id\"\n",
    "        x_columns = [x for x in self.test_data.columns if x not in [ID]]\n",
    "        x_test = self.test_data[x_columns]\n",
    "#         lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "        y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "        print(y_pred)\n",
    "        f1 = open(\"E:/招行数据比赛/data_b/评分数据集b/b/提交结果.txt\",\"w\")\n",
    "        for i in y_pred:\n",
    "            f1.writelines(str(i)+'\\n')\n",
    "        f1.close()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    pred = Credit_risk_scorePreLR()\n",
    "    gbm_model = pred.train_model()\n",
    "    pred.evaluate(gbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
